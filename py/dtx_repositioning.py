# -*- coding: utf-8 -*-
"""DTx_repositioning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KTe5h9TXBaqSABZvrVGbfQdka1CnxJEK
"""

cd /content/drive/Shareddrives/eunji

import pandas as pd
import pickle

"""## 분포 확인

### drug

#### all
"""

with open('data/disease/shared_drugs_psychiatric_n_behavioral.pickle', 'rb') as f:
# with open('data/disease/shared_drugs_all.pickle', 'rb') as f:
    drugs = pickle.load(f)

hist = sum(drugs.values.tolist(), [])

pd.Series(hist).describe()

type(hist[0])

len(hist)

import matplotlib.pyplot as plt
import seaborn as sns

hist = list(filter(lambda a: a > 0, hist))
print(len(hist))

plt.figure(figsize=(25,5))
sns.histplot(hist)

pd.Series(hist).describe() # drug

"""#### psychiatric"""

with open('shared_drugs_psychiatric.pickle', 'rb') as f:
# with open('shared_drugs_all.pickle', 'rb') as f:
    drugs = pickle.load(f)

hist = sum(drugs.values.tolist(), [])

pd.Series(hist).describe()

import matplotlib.pyplot as plt
import seaborn as sns

hist = list(filter(lambda a: a != 0, hist))
sns.histplot(hist)

pd.Series(hist).describe() # drug

"""### patent

#### all
"""

with open('shared_technologies_psychiatric.pickle', 'rb') as f:
# with open('shared_technologies_all.pickle', 'rb') as f:
    technologies = pickle.load(f)

technologies

hist = sum(technologies.values.tolist(), [])

pd.Series(hist).describe()

import matplotlib.pyplot as plt
import seaborn as sns

hist = list(filter(lambda a: a != 0, hist))
sns.histplot(hist)

pd.Series(hist).describe() # tech

"""#### psychiatric"""

with open('shared_technologies_psychiatric.pickle', 'rb') as f:
# with open('shared_technologies_all.pickle', 'rb') as f:
    technologies = pickle.load(f)

technologies

hist = sum(technologies.values.tolist(), [])

pd.Series(hist).describe()

import matplotlib.pyplot as plt
import seaborn as sns

hist = list(filter(lambda a: a != 0, hist))
sns.histplot(hist)

pd.Series(hist).describe() # tech

"""### gene"""

genes = pd.read_csv('gene_similarity.csv')
# genes = pd.read_csv('gene_similarity_psychiatric_top30.csv')

genes.jaccard_genes.describe()

# genes = genes[genes['jaccard_genes'] > 0.5]

genes1 = genes.copy()

################ gene_sim 변환 ################
import numpy as np
def normalize(x):
    min_x = 0 # 완전 0인 것과 구분을 위해
    return((x-min_x)/(np.max(x)-min_x))

genes1['jaccard_genes_scaled'] = normalize(genes1['jaccard_genes'])

genes1[['diseaseid1', 'diseaseid2']].duplicated()

import networkx as nx
from operator import itemgetter
from networkx.linalg.graphmatrix import adjacency_matrix

def to_adjacency_matrix(weighted_data):
    g = nx.DiGraph()
    edgeList = weighted_data.values.tolist()
    for i in range(len(edgeList)):
        g.add_edge(edgeList[i][0], edgeList[i][1], weight=edgeList[i][2])
    return g, nx.adjacency_matrix(g).A

g, mat = to_adjacency_matrix(genes1[['diseaseid1', 'diseaseid2', 'jaccard_genes_scaled']])

tri_upper_no_diag = np.triu(mat, k=1) # diagonal 지우고 upper matrix => 본인-본인 관계 제거, 두 번 반복되는 거 방지
np.argwhere( tri_upper_no_diag > 0 ).shape # shared drug인 disease

genes1 = pd.DataFrame(mat, index=g.nodes(), columns=g.nodes())

import matplotlib.pyplot as plt
import seaborn as sns

sns.histplot(genes1['jaccard_genes'])

"""## pair 별 similarity

### disease_df 생성
"""

diseases_index = list(set(list(set(list(genes['diseaseid1']) + list(genes['diseaseid2']))) + list(technologies.index) + list(drugs.index))) # 전체 disease로 이루어진 행렬 생성을 위해 합집합 계산

len(diseases_index)

from itertools import permutations

disease_df = pd.DataFrame(list(permutations(diseases_index, 2)), columns=['diseaseid1', 'diseaseid2']) # disease pair로 이루어진 df 생성

disease_df = pd.merge(disease_df, genes, on=['diseaseid1', 'diseaseid2']) # gene similarity 붙이기

"""#### all"""

from tqdm import tqdm

disease_df['drugs'] = 0

# drug similarity 정보 추가
for id1 in tqdm(drugs.index):
    for id2 in drugs.columns:
        disease_df['drugs'][(disease_df['diseaseid1'] == id1) & (disease_df['diseaseid2'] == id2)] = drugs.loc[id1, id2]

sum(disease_df['drugs'] != 0) # drugs pair 56개

disease_df['patents'] = 0

# patent similarity 정보 추가
for id1 in tqdm(technologies.index):
    for id2 in technologies.columns:
        disease_df['patents'][(disease_df['diseaseid1'] == id1) & (disease_df['diseaseid2'] == id2)] = technologies.loc[id1, id2]

sum(disease_df['patents'] != 0) # patents pair 65개

import pickle

with open('disease_similarity_all_0726.pickle', 'wb') as f:
    pickle.dump(disease_df, f)

def normalize(x):
    min_x = 0 # 완전 0인 것과 구분을 위해
    return((x-min_x)/(np.max(x)-min_x))

# 0-1 사이의 값으로 통일
import numpy as np
disease_df['jaccard_genes'] = normalize(disease_df['jaccard_genes'])
disease_df['drugs'] = normalize(disease_df['drugs'])
disease_df['patents'] = normalize(disease_df['patents'])

disease_df['item_set'] = [str(set(item)) for item in disease_df[['diseaseid1', 'diseaseid2']].values] # 중복된 pair 제거

disease_df.duplicated('item_set').sum()

duplicated_df = disease_df[disease_df.duplicated('item_set', keep=False)].sort_values('item_set')

(duplicated_df[['drugs', 'patents']].iloc[0] == duplicated_df[['drugs', 'patents']].iloc[1]).sum()

duplicated_df2 = duplicated_df.copy() # 혹시 모르니

idx = []
for i in range(int(len(duplicated_df)/2)):
    if (duplicated_df[['drugs', 'patents']].iloc[2*i] == duplicated_df[['drugs', 'patents']].iloc[2*i+1]).sum() != 2: # 두 칼럼 값이 다른 경우
        idx.append(2*i)

print(duplicated_df.iloc[idx, :].shape)
print(duplicated_df.shape)

for i in idx:
    if duplicated_df.iloc[i:i+2,:]['item_set'].nunique() == 1: # 같은 값으로 변환
        duplicated_df.iloc[i:i+2,:]['drugs'] = duplicated_df.iloc[i:i+2,:]['drugs'].max()
        duplicated_df.iloc[i:i+2,:]['patents'] = duplicated_df.iloc[i:i+2,:]['patents'].max()

duplicated_df.duplicated(['item_set'])

disease_df.drop(index=duplicated_df.index[duplicated_df.duplicated(['item_set'])], inplace=True)

disease_df['sum'] = disease_df['jaccard_genes'] + disease_df['drugs'] + disease_df['patents']
disease_df['max'] = disease_df[['jaccard_genes', 'drugs', 'patents']].max(axis=1, skipna=True)

sum(disease_df['sum'] != disease_df['max'])

disease_df[disease_df['sum'] != disease_df['max']]

import pickle

with open('disease_similarity_all_0726.pickle', 'wb') as f:
    pickle.dump(disease_df, f)

"""#### psychiatric"""

from tqdm import tqdm

disease_df['drugs'] = 0

# drug similarity 정보 추가
for id1 in tqdm(drugs.index):
    for id2 in drugs.columns:
        disease_df['drugs'][(disease_df['diseaseid1'] == id1) & (disease_df['diseaseid2'] == id2)] = drugs.loc[id1, id2]

sum(disease_df['drugs'] != 0) # drugs pair 56개

disease_df['patents'] = 0

# patent similarity 정보 추가
for id1 in tqdm(technologies.index):
    for id2 in technologies.columns:
        disease_df['patents'][(disease_df['diseaseid1'] == id1) & (disease_df['diseaseid2'] == id2)] = technologies.loc[id1, id2]

sum(disease_df['patents'] != 0) # patents pair 65개

def normalize(x):
    min_x = 0 # 완전 0인 것과 구분을 위해
    return((x-min_x)/(np.max(x)-min_x))

# 0-1 사이의 값으로 통일
disease_df['jaccard_genes'] = normalize(disease_df['jaccard_genes'])
disease_df['drugs'] = normalize(disease_df['drugs'])
disease_df['patents'] = normalize(disease_df['patents'])

disease_df['item_set'] = [str(set(item)) for item in disease_df[['diseaseid1', 'diseaseid2']].values] # 중복된 pair 제거

disease_df.duplicated('item_set').sum()

duplicated_df = disease_df[disease_df.duplicated('item_set', keep=False)].sort_values('item_set')

(duplicated_df[['drugs', 'patents']].iloc[0] == duplicated_df[['drugs', 'patents']].iloc[1]).sum()

duplicated_df2 = duplicated_df.copy() # 혹시 모르니

idx = []
for i in range(int(len(duplicated_df)/2)):
    if (duplicated_df[['drugs', 'patents']].iloc[2*i] == duplicated_df[['drugs', 'patents']].iloc[2*i+1]).sum() != 2: # 두 칼럼 값이 다른 경우
        idx.append(2*i)

print(duplicated_df.iloc[idx, :].shape)
print(duplicated_df.shape)

for i in idx:
    if duplicated_df.iloc[i:i+2,:]['item_set'].nunique() == 1: # 같은 값으로 변환
        duplicated_df.iloc[i:i+2,:]['drugs'] = duplicated_df.iloc[i:i+2,:]['drugs'].max()
        duplicated_df.iloc[i:i+2,:]['patents'] = duplicated_df.iloc[i:i+2,:]['patents'].max()

duplicated_df.duplicated(['item_set'])

disease_df.drop(index=duplicated_df.index[duplicated_df.duplicated(['item_set'])], inplace=True)

disease_df['sum'] = disease_df['jaccard_genes'] + disease_df['drugs'] + disease_df['patents']
disease_df['max'] = disease_df[['jaccard_genes', 'drugs', 'patents']].max(axis=1, skipna=True)

sum(disease_df['sum'] != disease_df['max'])

disease_df[disease_df['sum'] != disease_df['max']]

import pickle

with open('disease_similarity_psychiatric_0724.pickle', 'wb') as f:
    pickle.dump(disease_df, f)

"""### 분포 확인"""

import matplotlib.pyplot as plt
import seaborn as sns

sns.histplot(disease_df['sum'])

disease_df[disease_df['sum'] > 1]

disease_df.loc[disease_df['sum'] != disease_df['jaccard_genes'], ['jaccard_genes', 'drugs', 'patents']]

corr = disease_df.loc[disease_df['drugs'] != 0, ['jaccard_genes', 'drugs']].corr()
print(corr)

import matplotlib.pyplot as plt
import seaborn as sns

sns.heatmap(corr, cmap = plt.cm.PuBu)
plt.show()

disease_df.loc[disease_df['patents'] != 0, ['jaccard_genes', 'patents']]

corr = disease_df.loc[disease_df['patents'] != 0, ['jaccard_genes', 'patents']].corr()
print(corr)

import matplotlib.pyplot as plt
import seaborn as sns

sns.heatmap(corr, cmap = plt.cm.PuBu)
plt.show()

disease_df.loc[((disease_df['drugs'] != 0) & (disease_df['patents'] != 0)), ['jaccard_genes', 'drugs', 'patents']]

corr = disease_df.loc[((disease_df['drugs'] != 0) & (disease_df['patents'] != 0)), ['jaccard_genes', 'drugs', 'patents']].corr()
print(corr)

import matplotlib.pyplot as plt
import seaborn as sns

sns.heatmap(corr, cmap = plt.cm.PuBu)
plt.show()

"""## Case Study"""

def find_by_wipsonkey(wipsonkey_list, threshold=0):
    '''
    특허번호를 입력하면 해당 특허가 타겟팅하는 질병과 유사한 질병 정보 제공
    '''

    disease_ex = list(set([label_flattened.CUI_list.iloc[idx] for idx, key in enumerate(label_flattened['wipsonkey']) if key in wipsonkey_list]))
    disease_ex = [disease for disease in disease_ex if disease in filt.keys()]#; disease_ex

    results = {'origin': [], 'origin_name': [], 'target': [], 'target_name': [], 'genomic': [], 'chemical': [], 'technological': [], 'similarity_sum': []}

    for d in disease_ex:
        if len(disease_df[disease_df['diseaseid1'] == d]) != 0:
            results['origin'].append(d)
            results['origin_name'].append(filt[d])
            results['target'].append(disease_df.loc[disease_df['diseaseid1'] == d, 'diseaseid2'].values[0])
            try:
                results['target_name'].append(filt[disease_df.loc[disease_df['diseaseid1'] == d, 'diseaseid2'].values[0]])
            except:
                results['target_name'].append(disease_df.loc[disease_df['diseaseid1'] == d, 'diseaseid2'].values[0])
            results['genomic'].append(disease_df.loc[disease_df['diseaseid1'] == d, 'jaccard_genes'].values[0])
            results['chemical'].append(disease_df.loc[disease_df['diseaseid1'] == d, 'drugs'].values[0])
            results['technological'].append(disease_df.loc[disease_df['diseaseid1'] == d, 'patents'].values[0])
            results['similarity_sum'].append(disease_df.loc[disease_df['diseaseid1'] == d, 'sum'].values[0])
            # results['similarity_max'].append(disease_df.loc[disease_df['diseaseid1'] == d, 'max'].values[0])
        if len(disease_df[disease_df['diseaseid2'] == d]) != 0:
            results['origin'].append(d)
            results['origin_name'].append(filt[d])
            results['target'].append(disease_df.loc[disease_df['diseaseid2'] == d, 'diseaseid1'].values[0])
            try:
                results['target_name'].append(filt[disease_df.loc[disease_df['diseaseid2'] == d, 'diseaseid1'].values[0]])
            except:
                results['target_name'].append(disease_df.loc[disease_df['diseaseid2'] == d, 'diseaseid1'].values[0])
            results['genomic'].append(disease_df.loc[disease_df['diseaseid2'] == d, 'jaccard_genes'].values[0])
            results['chemical'].append(disease_df.loc[disease_df['diseaseid2'] == d, 'drugs'].values[0])
            results['technological'].append(disease_df.loc[disease_df['diseaseid2'] == d, 'patents'].values[0])
            results['similarity_sum'].append(disease_df.loc[disease_df['diseaseid2'] == d, 'sum'].values[0])
            # results['similarity_max'].append(disease_df.loc[disease_df['diseaseid2'] == d, 'max'].values[0])

    results = pd.DataFrame(results)
    results = results[results['similarity_sum'] > threshold].sort_values(['origin_name','similarity_sum'], ascending=False)[['origin_name', 'target_name', 'similarity_sum', 'genomic', 'chemical', 'technological', 'origin', 'target']]

    return results

def find_by_cui(cui_list, threshold=0):
    '''
    cui list를 입력하면 유사한 disease 정보 제공
    '''

    results = {'origin': [], 'origin_name': [], 'target': [], 'target_name': [], 'genomic': [], 'chemical': [], 'technological': [], 'similarity_sum': []}

    for d in cui_list:
        if len(disease_df[disease_df['diseaseid1'] == d]) != 0:
            results['origin'].append(d)
            results['origin_name'].append(filt[d])
            results['target'].append(disease_df.loc[disease_df['diseaseid1'] == d, 'diseaseid2'].values[0])
            try:
                results['target_name'].append(filt[disease_df.loc[disease_df['diseaseid1'] == d, 'diseaseid2'].values[0]])
            except:
                results['target_name'].append(disease_df.loc[disease_df['diseaseid1'] == d, 'diseaseid2'].values[0])
            results['genomic'].append(disease_df.loc[disease_df['diseaseid1'] == d, 'jaccard_genes'].values[0])
            results['chemical'].append(disease_df.loc[disease_df['diseaseid1'] == d, 'drugs'].values[0])
            results['technological'].append(disease_df.loc[disease_df['diseaseid1'] == d, 'patents'].values[0])
            results['similarity_sum'].append(disease_df.loc[disease_df['diseaseid1'] == d, 'sum'].values[0])
            # results['similarity_max'].append(disease_df.loc[disease_df['diseaseid1'] == d, 'max'].values[0])
        if len(disease_df[disease_df['diseaseid2'] == d]) != 0:
            results['origin'].append(d)
            results['origin_name'].append(filt[d])
            results['target'].append(disease_df.loc[disease_df['diseaseid2'] == d, 'diseaseid1'].values[0])
            try:
                results['target_name'].append(filt[disease_df.loc[disease_df['diseaseid2'] == d, 'diseaseid1'].values[0]])
            except:
                results['target_name'].append(disease_df.loc[disease_df['diseaseid2'] == d, 'diseaseid1'].values[0])
            results['genomic'].append(disease_df.loc[disease_df['diseaseid2'] == d, 'jaccard_genes'].values[0])
            results['chemical'].append(disease_df.loc[disease_df['diseaseid2'] == d, 'drugs'].values[0])
            results['technological'].append(disease_df.loc[disease_df['diseaseid2'] == d, 'patents'].values[0])
            results['similarity_sum'].append(disease_df.loc[disease_df['diseaseid2'] == d, 'sum'].values[0])
            # results['similarity_max'].append(disease_df.loc[disease_df['diseaseid2'] == d, 'max'].values[0])

    results = pd.DataFrame(results)
    results = results[results['similarity_sum'] > threshold].sort_values(['origin_name','similarity_sum'], ascending=False)[['origin_name', 'target_name', 'similarity_sum', 'genomic', 'chemical', 'technological', 'origin', 'target']]

    return results

def find_exact_patents_from_list(wipsonkey_list=None, cui_list=None, ):
    '''
    wipsonkey list에서 특정 cui list를 포함하는 특허 추출 
    OR
    전체에서 특정 cui list를 포함하는 특허 추출
    '''

    if wipsonkey_list == None:
        s1 = label_flattened['wipsonkey'].notnull()
    else:
        s1 = label_flattened['wipsonkey'].apply(lambda x: x in wipsonkey_list)

    if cui_list == None:
        s2 = label_flattened['CUI_list'].notnull()
    else:
        if ~cui_list[0].startswith(tuple(set(pd.Series(filt.keys()).apply(lambda x: x[:2])))):
            cui_list = [key for key, value in filt.items() if value in cui_list]
        s2 = label_flattened['CUI_list'].apply(lambda x: x in cui_list)
    # print(s2.sum())

    s3 = label_flattened.loc[s1.multiply(s2)].drop_duplicates(['CUI_list', 'wipsonkey'])
    s3['disease_name'] = s3['CUI_list'].apply(lambda x: filt[x] if x in filt.keys() else x)

    return s3.drop(columns = '_id')

def find_by_regex(regex, ):
    '''
    regex를 통해 disease 정보(cui, name) 추출
    '''

    import re
    from pprint import pprint
    p = re.compile(regex.lower())
    disease_dict = {disease: filt[disease] for disease in filt.keys() if len(p.findall(filt[disease].lower())) > 0}
    pprint(disease_dict)
    return disease_dict.keys(), disease_dict.values()

def find_new_diseases(wipsonkey_list, threshold):
    '''
    기존에 target으로 하는 disease list와 새로운 disease list
    '''
    results = find_by_wipsonkey(wipsonkey_list, threshold) # 특허가 타겟으로 하는 전체 질병
    results2 = find_exact_patents_from_list(wipsonkey_list) # 특허가 타겟으로 하는 질병의 유사한 질병
    results2 = results2.drop_duplicates('disease_name')
    results_list = results2['CUI_list'] # 유사한 질병 중복 제거 (특허끼리 공통된 질병을 타겟으로 할 수 있기 때문)
    results = results[results['target'].apply(lambda x: x not in list(results_list))] # 특허가 이미 타겟으로 하는 질병 제거
    results = results[results['origin'].apply(lambda x: x not in list(results['target']))] # 유사한 질병들 중 이미 기존 특허의 타겟인 질병 제거
    return results2[['disease_name', 'CUI_list']], results

"""### psychiatric"""

import pickle

with open('disease_similarity_all_0724.pickle', 'rb') as f:
    disease_df = pickle.load(f)

import pickle
with open('mental_and_behavioral_CUIs_final_0726.pickle', 'rb') as f:
    filt = pickle.load(f)

filt = {filt['cui'][k]: filt['name'][k] for k in range(len(filt['cui']))}

# # psychiatric은 아니지만 보기 편하게 추가
# filt['C0270541'] = 'Rebound insomnia'
# filt['C0003467'] = 'anxiety'
# filt['C0454655'] = 'Semantic-pragmatic disorder'
# filt['C0026769'] = 'Multiple sclerosis'
# filt['C0013222'] = 'Disorder, Drug Use'

import pandas as pd
import ast

label = pd.read_csv('disease_label_07231102.csv')
label = label[label['CUI_list'].notnull()]
label.CUI_list = label.CUI_list.apply(lambda x: ast.literal_eval(x)) # str으로 작성된 list를 list 형식으로
label_flattened = label.explode('CUI_list')

disease_df[(disease_df['patents'] > 0) | (disease_df['drugs'] > 0)].describe()

"""#### 회사가 가진 특허의 타겟과 유사한 질병 추출"""

wipsonkey_list = [5420043005578, 5420043000406, 5420035000449, 5420045005146, 5420025000388, 4921017006586, 5420048005573] # "Pear Therapeutics, Inc."
results = find_by_wipsonkey(wipsonkey_list, 0.5)

results
# C0013222: disorder, drug use
# C0270541: Rebound insomnia

wipsonkey_list = [5420043005578, 5420019005994] # "Pear Therapeutics, Inc. & Novartis"
results = find_by_wipsonkey(wipsonkey_list, 0.5)

results
# C0013222: disorder, drug use
# C0270541: Rebound insomnia

"""#### 특정 질환과 유사한 질환 추출"""

# regex를 사용하여 추출
cui_list, regex_names = find_by_regex('sclerosis')

# 직접 cui 입력
# cui_list = ['C0033975', 'C0917799', 'C0349255', 'C0541798', 'C0917801', 'C0030319', 'C0236969', 'C0033139', 'C0008074', 'C0038436', 'C0751249', 'C0001546', 'C0036358', 'C0524528', 
#             'C0011579', 'C0036341', 'C0036337', 'C0011251', 'C0086769', 'C0033958', 'C0027932', 'C0011206', 'C0036349']

# cui_list = list(set(list(disease_df.loc[disease_df['patents'] > 0,'diseaseid1']) + list(disease_df.loc[disease_df['patents'] > 0, 'diseaseid2']))) # patents가 0 초과인 cui만 추출

find_by_cui(cui_list)

"""#### 특허 리스트 중 특정 질환을 타겟으로 하는 특허 추출

ex. pear therapeutics가 가진 특허들 중 brief reactive psychosis를 타겟으로 하는 특허가 어떤 특허인지 확인
"""

find_exact_patents_from_list(cui_list=['brief reactive psychosis'], wipsonkey_list=wipsonkey_list)

# "Electronic Devices and Methods for Treatment of Depressive Symptoms, Depressive Disorders Utilizing Digital Therapies" "Pear Therapeutics, Inc."
# brief reactive psychosis => schizophreniform disorder 에도 사용 가능.

results = find_exact_patents_from_list(wipsonkey_list=[5420043005578, 5420019005994]);
results.drop_duplicates('disease_name')

results = find_exact_patents_from_list(cui_list=['C0011265']);
results.drop_duplicates('disease_name')

"""#### 특허가 기존에 타겟으로 삼지 않았으나 새로 발견된 질병
적절한 threshold를 정해줄 필요가 있긴 하다.
"""

'''
"Pear Therapeutics, Inc. & Novartis"
Multiple Sclerosis 환자들의 depression을 감소할 수 있는 DTx(app)을 개발.
=> https://www.fiercebiotech.com/medtech/pear-novartis-begin-testing-a-conversational-app-for-ms-related-depression
'''

wipsonkey_list = [5420043005578, 5420019005994]

original_target, new_target = find_new_diseases(wipsonkey_list, 0.3)

'''
해당 기술은 insomnia와 정신 분열증 등의 질병을 target으로 하고 있으나,
'''

original_target[original_target['disease_name'] != original_target['CUI_list']]

new_target

'''
ADHD에도 활용이 가능함을 확인하였다.
'''

disease_df[disease_df['patents'] > 0].sort_values('sum', ascending=False)[:20]

